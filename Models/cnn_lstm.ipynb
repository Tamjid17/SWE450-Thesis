{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# DNS Tunneling Detection using CNN + LSTM\n",
        "\n",
        "This notebook implements a **CNN + LSTM** hybrid model for DNS tunneling detection â€” a strong baseline between pure CNN and CNN+BiLSTM models for fair comparison.\n",
        "\n",
        "Features:\n",
        "- Character-level embedding of subdomain/query names\n",
        "- Combined numeric + sequential input\n",
        "- Early stopping\n",
        "- Complete evaluation with ROC-AUC, confusion matrix, and training curves"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import classification_report, confusion_matrix, roc_curve, auc\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, Model, Input\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Load Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "DATA_PATH = \"dns_preprocessed_dataset_deduplicated1_(1).csv\"\n",
        "df = pd.read_csv(DATA_PATH)\n",
        "\n",
        "print(\"Dataset shape:\", df.shape)\n",
        "print(df.head())\n",
        "print(\"\\nLabel distribution:\")\n",
        "print(df['label'].value_counts())\n",
        "\n",
        "plt.figure(figsize=(6,4))\n",
        "df['label'].value_counts().sort_index().plot(kind='bar')\n",
        "plt.xticks([0,1], ['Normal', 'Tunneled'], rotation=0)\n",
        "plt.title('Class Distribution')\n",
        "plt.ylabel('Count')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Feature Selection & Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "TEXT_COL = 'qname_clean'\n",
        "NUMERIC_FEATURES = [\n",
        "    'qname_len', 'label_count', 'qtype', 'entropy',\n",
        "    'udp_length', 'ip_length', 'ttl', 'response_flag', 'dns_time'\n",
        "]\n",
        "\n",
        "# Remove empty queries\n",
        "df = df[df[TEXT_COL].astype(str).str.len() > 0].reset_index(drop=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Character-Level Encoding"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "all_text = ''.join(df[TEXT_COL].astype(str).tolist())\n",
        "chars = sorted(list(set(all_text)))\n",
        "char2idx = {c: i+1 for i, c in enumerate(chars)}\n",
        "vocab_size = len(char2idx) + 1\n",
        "\n",
        "MAX_SEQ_LEN = min(100, df[TEXT_COL].astype(str).str.len().max())\n",
        "\n",
        "def encode_qname(s, max_len=MAX_SEQ_LEN):\n",
        "    s = str(s)\n",
        "    seq = [char2idx.get(ch, 0) for ch in s[:max_len]]\n",
        "    if len(seq) < max_len:\n",
        "        seq += [0] * (max_len - len(seq))\n",
        "    return np.array(seq, dtype=np.int32)\n",
        "\n",
        "X_text = np.stack(df[TEXT_COL].apply(encode_qname))\n",
        "X_num = df[NUMERIC_FEATURES].astype(float).values\n",
        "y = df['label'].astype(int).values\n",
        "\n",
        "print(f\"Vocabulary size: {vocab_size}, Max sequence length: {MAX_SEQ_LEN}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Train / Validation / Test Split"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "X_text_train, X_text_temp, X_num_train, X_num_temp, y_train, y_temp = train_test_split(\n",
        "    X_text, X_num, y, test_size=0.3, stratify=y, random_state=42\n",
        ")\n",
        "\n",
        "X_text_val, X_text_test, X_num_val, X_num_test, y_val, y_test = train_test_split(\n",
        "    X_text_temp, X_num_temp, y_temp, test_size=0.5, stratify=y_temp, random_state=42\n",
        ")\n",
        "\n",
        "# Scale numeric features\n",
        "scaler = StandardScaler()\n",
        "X_num_train = scaler.fit_transform(X_num_train)\n",
        "X_num_val = scaler.transform(X_num_val)\n",
        "X_num_test = scaler.transform(X_num_test)\n",
        "\n",
        "print(f\"Train: {len(y_train)}, Val: {len(y_val)}, Test: {len(y_test)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Build CNN + LSTM Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "embedding_dim = 64\n",
        "num_filters = 128\n",
        "kernel_size = 5\n",
        "\n",
        "text_input = Input(shape=(MAX_SEQ_LEN,), name=\"text_input\")\n",
        "x = layers.Embedding(vocab_size, embedding_dim)(text_input)\n",
        "x = layers.Conv1D(num_filters, kernel_size, activation='relu')(x)\n",
        "x = layers.MaxPooling1D(pool_size=2)(x)\n",
        "x = layers.LSTM(64, return_sequences=False)(x)\n",
        "x = layers.Dense(64, activation='relu')(x)\n",
        "\n",
        "num_input = Input(shape=(X_num_train.shape[1],), name=\"num_input\")\n",
        "n = layers.Dense(32, activation='relu')(num_input)\n",
        "n = layers.Dense(32, activation='relu')(n)\n",
        "\n",
        "combined = layers.concatenate([x, n])\n",
        "combined = layers.Dense(64, activation='relu')(combined)\n",
        "output = layers.Dense(1, activation='sigmoid')(combined)\n",
        "\n",
        "cnn_lstm_model = Model(inputs=[text_input, num_input], outputs=output)\n",
        "cnn_lstm_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "cnn_lstm_model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Train the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "early_stop = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
        "\n",
        "history = cnn_lstm_model.fit(\n",
        "    [X_text_train, X_num_train], y_train,\n",
        "    validation_data=([X_text_val, X_num_val], y_val),\n",
        "    epochs=30,\n",
        "    batch_size=64,\n",
        "    callbacks=[early_stop],\n",
        "    verbose=1\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Training Curves"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "plt.figure(figsize=(12,4))\n",
        "\n",
        "plt.subplot(1,2,1)\n",
        "plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
        "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
        "plt.title('CNN + LSTM Accuracy')\n",
        "plt.legend()\n",
        "\n",
        "plt.subplot(1,2,2)\n",
        "plt.plot(history.history['loss'], label='Train Loss')\n",
        "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
        "plt.title('CNN + LSTM Loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8. Evaluation on Test Set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "test_probs = cnn_lstm_model.predict([X_text_test, X_num_test]).flatten()\n",
        "test_preds = (test_probs >= 0.5).astype(int)\n",
        "\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_test, test_preds, digits=4))\n",
        "\n",
        "cm = confusion_matrix(y_test, test_preds)\n",
        "print(\"Confusion Matrix:\\n\", cm)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 9. ROC Curve"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "fpr, tpr, _ = roc_curve(y_test, test_probs)\n",
        "roc_auc = auc(fpr, tpr)\n",
        "\n",
        "plt.figure(figsize=(7,6))\n",
        "plt.plot(fpr, tpr, label=f'ROC Curve (AUC = {roc_auc:.3f})', linewidth=2)\n",
        "plt.plot([0,1], [0,1], 'k--')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('ROC Curve - CNN + LSTM Model')\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.grid(True)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 10. Save Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "cnn_lstm_model.save(\"dns_cnn_lstm_model.h5\")\n",
        "print(\"CNN + LSTM model saved as 'dns_cnn_lstm_model.h5'\")"
      ]
    }
  ]
}